{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /DATA/solomiia.kurchaba/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /DATA/solomiia.kurchaba/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /DATA/solomiia.kurchaba/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /DATA/solomiia.kurchaba/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "local_dir = os.path.join(\"/DATA\",os.environ.get(\"USER\"),\"MNIST_data\")\n",
    "os.makedirs(local_dir,mode=0o755, exist_ok=True)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(local_dir, one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przygotowujemy dane i sieć zgodnie z opisem w pliku MNIST RNN\n",
    "\n",
    "(jedyna różnica, tym razem nie potrzebujemy zbioru testowego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 28 \n",
    "time_steps = 28 \n",
    "hidden = 128\n",
    "output_classes = 10\n",
    "lr=0.0001\n",
    "batch_size=128\n",
    "x_tr, y_batches = mnist.train.next_batch(batch_size)\n",
    "x_batches = x_tr.reshape(-1, time_steps, num_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed=10\n",
    "X=tf.placeholder(tf.float32,[None,time_steps,num_input])\n",
    "Y=tf.placeholder(tf.float32,[None,output_classes])\n",
    "x=tf.unstack(X,time_steps,1)\n",
    "basic_cell=tf.contrib.rnn.BasicRNNCell(num_units=hidden) # here the first set of weights and biases is defined\n",
    "rnn_output, states=rnn.static_rnn(basic_cell,x,dtype=tf.float32)\n",
    "stacked_rnn_output=tf.reshape(rnn_output[-1],[-1,hidden])\n",
    "stacked_outputs=tf.layers.dense(stacked_rnn_output,output_classes)# the output layer. (+additional set of weights and biases)\n",
    "predict=tf.nn.softmax(stacked_outputs)\n",
    "y_pred=tf.argmax(predict,1)\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predict, labels=Y))\n",
    "\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=lr)\n",
    "training_op=optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(predict, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładujemy obrazek, wcześniej narysowany w Paint, w formacie np.ndarray, oraz ręcznie przygotowujemy label do obrazka, tak podanie poprawnych danych wyjściowych jest obowiązkowe. Zmieniamy wymiar obrazku oraz lablu na zgodny z wymaganiami sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "im=misc.imread(\"two.png\",mode='L')\n",
    "l=[0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]\n",
    "lbl=np.array(l)\n",
    "lbl=lbl.reshape(-1,10)\n",
    "x_n=im.reshape(-1,time_steps,num_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAAAXNSR0IArs4c6QAAAARnQU1BAACx\njwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAADASURBVEhLvZZRDsAgCEPn7n9nZ2JisCLUxsxP\nw56lgK483qq1rtulFDfYiVy3XOIIY9B4eEzs6JSrQFP0BAWZVtGaQaD3Zb1vjLlQgVEslDy7h03Q\nvAJcV7GtN5TarHciWOjROFCeMs1rTc+VCgNGKQ1K79vC9EqaPlQsT5+5xgAqph93tAgF+eCPDr1w\noTD1HDG60uCYv6DN9b6OUrbBqJRkxafqbxTkYZvhjqf5mJIOBH8C29ln0OnzI5fa+fADjB9IIY3B\n08AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "im=Image(filename='two.png')\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktywacja cieci. Zamiast danych testowych ładujemy nasz obrazek. Na końcu wyświetlamy procent poprawnych odpowiedzi uzyskanych w ostatnim kroku iteracji treningowej, lable testowego obrazku, przewidziany przez sieć, oraz wynik na podstawie którego sieć robi wniosek że to trójka (wyjście z sieci po działaniu softmaxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tloss: 2.29418\n",
      "100 \tloss: 1.99204\n",
      "200 \tloss: 1.80027\n",
      "300 \tloss: 1.63319\n",
      "400 \tloss: 1.56301\n",
      "500 \tloss: 1.53374\n",
      "600 \tloss: 1.5202\n",
      "700 \tloss: 1.5151\n",
      "800 \tloss: 1.51263\n",
      "900 \tloss: 1.5111\n",
      "1000 \tloss: 1.51005\n",
      "1100 \tloss: 1.5093\n",
      "1200 \tloss: 1.50874\n",
      "1300 \tloss: 1.5083\n",
      "1400 \tloss: 1.50795\n",
      "1500 \tloss: 1.5076\n",
      "1600 \tloss: 1.50034\n",
      "1700 \tloss: 1.49999\n",
      "1800 \tloss: 1.49976\n",
      "1900 \tloss: 1.49958\n",
      "2000 \tloss: 1.49942\n",
      "2100 \tloss: 1.49926\n",
      "2200 \tloss: 1.4919\n",
      "2300 \tloss: 1.49162\n",
      "2400 \tloss: 1.49115\n",
      "0.984375\n",
      "[3]\n",
      "[[  4.80813952e-03   3.73418964e-02   6.12823144e-02   8.23082745e-01\n",
      "    9.70509354e-05   4.67024855e-02   7.42168492e-03   2.41419976e-03\n",
      "    1.00439526e-02   6.80556148e-03]]\n"
     ]
    }
   ],
   "source": [
    "epochs=2500\n",
    "with  tf.Session() as sess:\n",
    "    init.run()\n",
    "    for ep in range(epochs):\n",
    "        sess.run(training_op,feed_dict={X: x_batches, Y: y_batches})\n",
    "        loss=loss_op.eval(feed_dict={X: x_batches, Y: y_batches})\n",
    "        if ep % 100 == 0:\n",
    "            loss=loss_op.eval(feed_dict={X: x_batches, Y: y_batches})\n",
    "            print(ep,\"\\tloss:\",loss)\n",
    "    train_accuracy=accuracy.eval(feed_dict={X: x_batches, Y: y_batches})  \n",
    "    print(train_accuracy)\n",
    "    y_pred=y_pred.eval(feed_dict={X: x_n, Y: lbl})\n",
    "    print(y_pred)\n",
    "    predict=predict.eval(feed_dict={X: x_n, Y: lbl})\n",
    "   \n",
    "    print(predict)\n",
    "    \n",
    "        \n",
    "        \n",
    "sess.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
